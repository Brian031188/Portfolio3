---
title: "1361_Project_Proposal"
author: "Brian Forristal"
date: "1/26/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(tidyr)
library(methods)
library(plotly)

# Tidy Data 
library(tidyr)
library(tidyverse)
library(tidyselect)
library(lubridate)

# Data Visualization
library(ggplot2)

# Decision Tree Modeling and other
library(tree)
library(modelr)
library(randomForest)

# Reading excel files directly into script
library(readxl)

# Stepwise linear regression functions
library(olsrr)

# For bootstrapping and resampling
library(rsample)
library(ISLR)
library(purrr)
library(mdsr)

library(factoextra)
library(fivethirtyeight)

#SVM
library(e1071)
library(MVN)
library(mvnormtest)
library(ICSNP)
library(car)
```

# Is The Quality of Wine Purely Subjective?
## Data Import
```{r}
Red = read.csv("wine_quality_red.csv")
White = read.csv("wine_quality_white.csv")
```

The datasets will work for regression because the quality metric is ordinal. Meaning that a quality score of 6.7 is easily understood to be between 6 and 7 but closer to 7. The data can also be arranged such that there is the potential to do classification as to the category of wine, red or white, based on the features in the data. There are 12 features, 1 response, 6,497 observations, and no missing data. 

## Verify Feature and Observation Dimensions
```{r}
# Add categorical predictor to each dataset then combine them
White = White %>% 
  mutate(color = "White")

df = Red %>% 
  mutate(color = "Red") %>% 
  bind_rows(White) %>% 
  mutate(color = as.factor(color))


# There appear to be no missing values
dim(df %>% 
  na.omit())
# 6,497 observations, 12 predictors, 1 independent variable
dim(df)
```



## Feature Correlations
There are several features which are correlated with quality, a subjective measure, and of those there may be evidence of collinearity. This seems intuitive because the combinations of the features create wine itself. What quantities of each will generate a high quality score?
```{r}
# Correlation Matrix
df %>%
  select(-color) %>% 
  cor()

# Scatter plots of quality to alcohol, quality to density, alcohol to density.
set.seed(1)
ggplot(df %>% 
         sample_frac(size = 0.1), aes(x = alcohol, y = density)) +
  geom_point(position = position_jitter(width = 0.05, height = 0.01)) +
  geom_smooth()
ggplot(df %>% 
         sample_frac(size = 0.1), aes(x = alcohol, y = quality, color = color)) +
  geom_point() 
ggplot(df %>% 
         sample_frac(size = 0.1), aes(x = density, y = quality, color = color)) +
  geom_point() 
```

## Histograms
Several of the features in the data appear to follow a normal probability distribution. 
```{r}
# Alcohol
ggplot(df, aes(x = alcohol)) + 
 geom_histogram(aes(y=..density..), colour = "black", fill = "white", bins = 30)+
 geom_density(alpha = 0.2, fill = "#FF6666") +
 facet_grid(cols = vars(color)) 

# Fixed acidity
ggplot(df, aes(x = fixed.acidity)) + 
 geom_histogram(aes(y=..density..), colour = "black", fill = "white", bins = 30)+
 geom_density(alpha = 0.2, fill = "#FF6666") +
 facet_grid(cols = vars(color)) 

# Volatile acidity
ggplot(df, aes(x = volatile.acidity)) + 
 geom_histogram(aes(y=..density..), colour = "black", fill = "white", bins = 30)+
 geom_density(alpha = 0.2, fill = "#FF6666") +
 facet_grid(cols = vars(color)) 

# Citric acid
ggplot(df, aes(x = citric.acid )) +
 geom_histogram(aes(y=..density..), colour = "black", fill = "white", bins = 30)+
 geom_density(alpha = 0.2, fill = "#FF6666") +
 facet_grid(cols = vars(color)) 
```

## Initial Analysis
We will perform an initial analysis of several predictive models on the data to determine if relationships exist among the features that are worth investigating further.
```{r}
# Random training and test sets
set.seed(1)
data_vector = sample(1:6497, (0.8*6497))
train = df[data_vector, 1:13]
test = df[-data_vector, 1:13]

# Simple linear regression with quality on alcohol (the feature with highest correlation to response)
mod1 = lm(quality ~ alcohol, train)
summary(mod1)

# Test MSE
simple_MSE = test %>% 
  add_predictions(mod1) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )

test %>% 
  add_predictions(mod1)
  
# Stepwise multiple linear regression model
## Select features 
mod2 = lm(quality ~., train)
mod_select = ols_step_both_p(mod2)

# Train model
mod2 = lm(quality ~ alcohol + volatile.acidity + sulphates + residual.sugar + color + density + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + pH + fixed.acidity, train)
summary(mod2)

# Test MSE
multiple_MSE = test %>% 
  add_predictions(mod2) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )

# Random Forest
mod3 = randomForest(quality ~., train, ntree = 1000,  mtry = 4, importance = TRUE)
mod3

# Test MSE
ranforest_MSE = test %>% 
  add_predictions(mod3) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )

# Summary of test MSE values
simple_MSE
multiple_MSE
ranforest_MSE
```
## Preliminary Conclusions
As it is possible to see from the initial analysis, there are parametric and nonparametric metohds capable of making relatively accurate predictions with minimal alteration of the data. The next step will be to see how the introduction of interaction, polynomial, and random noise features into the dataset will affect the predictive strength of each method; and ultimately which method is best. Also, a deeper analysis into each method would be beneficial to learn the distribution of MSE values based on permuations of the training and test sets.

# Classification
```{r}
set.seed(1)
data_vector = sample(1:6497, (0.8*6497))
df_train = df[data_vector, 1:13]
df_test = df[-data_vector, 1:13]


  df %>% 
    ggplot(aes(x = scale(log(alcohol)))) + 
    geom_histogram(aes(y=..density..), colour = "black", fill = "white", bins = 30) +
    geom_density(alpha = 0.2, fill = "#FF6666")

```
# LDA
```{r}
# library(MASS)
# set.seed(1)
# mod1 = lda(color ~., df_train)
# 
# # Predicts test set
# mod1_pred = predict(mod1, df)$class
# 
# # Confusion matrix of predictions vs truth
# truth = df$color
# predictions = mod1_pred
# table(truth, predictions)

```

# QDA
```{r}
# set.seed(1)
# mod2 = qda(color ~., df_train)
# 
# # Predicts test set
# mod2_pred = predict(mod2, df)$class
# 
# # Confusion matrix of predictions vs truth
# truth = df$color
# predictions = mod2_pred
# table(truth, predictions)
# detach()
```

# Permutation Testing

```{r}

df = read_csv("wine_df_scaled.csv")

set.seed(1)
data_vector = sample(1:6497, (0.8*6497))
df_train = df[data_vector, 1:13]
df_test = df[-data_vector, 1:13]

# takes 23 seconds
mod3 = randomForest(quality ~ alcohol + density + pH, df_train, ntree = 1000,  mtry = 2, importance = TRUE)

mod3test = df_test %>% 
  add_predictions(mod3) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )

mod3test


mseList = list()
n = c(1:100)

for(i in n) {
  
set.seed(1)
data_vector = sample(1:6497, (0.8*6497))

set.seed(i)
df = df %>% 
  mutate(density = shuffle(df$density, replace = F))

df_train = df[data_vector, 1:13]
df_test = df[-data_vector, 1:13]


mod4 = randomForest(quality ~ alcohol + density + pH, df_train, ntree = 1000,  mtry = 2, importance = TRUE)

mseList[[i]] = df_test %>% 
  add_predictions(mod4) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )

}

X1 = bind_rows(mseList)
X2 = bind_rows(mseList)
X3 = bind_rows(mseList)


X1 %>% 
  ggplot(aes(x = MSE)) + 
    geom_histogram(aes(y=..density..), colour = "black", fill = "white", bins = 30) +
    geom_density(alpha = 0.2, fill = "#FF6666") +
    geom_vline(aes(xintercept = mod3test$MSE), colour = "red")

X2 %>% 
  ggplot(aes(x = MSE)) + 
    geom_histogram(aes(y=..density..), colour = "black", fill = "white", bins = 30) +
    geom_density(alpha = 0.2, fill = "#FF6666") +
    geom_vline(aes(xintercept = mod3test$MSE), colour = "red")

X3 %>% 
  ggplot(aes(x = MSE)) + 
    geom_histogram(aes(y=..density..), colour = "black", fill = "white", bins = 30) +
    geom_density(alpha = 0.2, fill = "#FF6666") +
    geom_vline(aes(xintercept = mod3test$MSE), colour = "red")

```

```{r}
df = read_csv("wine_df_scaled.csv")

set.seed(1)
data_vector = sample(1:6497, (0.8*6497))
train = df[data_vector, 1:13]
test = df[-data_vector, 1:13]

library(caret)

n = c(5, 10)
resultsList = list()

for(i in n) {

set.seed(1)
trControl <- trainControl(method  = "cv",
                          number  = i)

fit <- train(color ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = 1:20),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = df)

resultsList[[i]] = fit$results %>% 
  data.frame() %>% 
  select(k, Accuracy) %>% 
  mutate(folds = i)

}

bind_rows(resultsList) %>%
  mutate(folds = ifelse(folds == 5, "five", "ten")) %>% 
  ggplot(aes(x = k, y = Accuracy, color = folds)) +
  geom_line() 

lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=10))
trControl = trainControl(method = "cv",
                         number = 10)
model.cv = train(quality ~.,
                 data = wine,
                 method = "ridge", 
                 trControl = trControl, 
                 preProcess = c("scale", "BoxCox"), 
                 tuneGrid = lambdaGrid, 
                 na.action = na.omit)

model.cv = train(quality ~.,
                 data = train,
                 method = "ridge", 
                 trControl = trControl, 
                 preProcess = c("scale", "BoxCox"), 
                 lambda = 0.01, 
                 na.action = na.omit)

test %>% 
  mutate(predictions = predict(model.cv, test)) %>% 
  summarize(
    N = n(), SSE = sum((predictions - quality)*(predictions - quality)), MSE = SSE/N,
  )

model.cv2 = train(quality ~.,
                 data = train,
                 method = "lasso", 
                 trControl = trControl, 
                 preProcess = c("scale", "BoxCox"), 
                 na.action = na.omit)

test %>% 
  mutate(predictions = predict(model.cv2, test)) %>% 
  summarize(
    N = n(), SSE = sum((predictions - quality)*(predictions - quality)), MSE = SSE/N,
  )

```

This library is nuts! I can build almost any model type with cross-validation and make predictions in the smallest amount of code! This is great.
```{r}

# multiple linear
set.seed(1)
trControl <- trainControl(method  = "cv",
                          number  = 10)

fit <- train(quality ~ .,
             method     = "lm",
             trControl  = trControl,
             data       = train)

test %>% 
  mutate(pred = predict(fit, test)) %>% 
   summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N,
  )

# stepwise with this type of setup doesn't work for some reason. A more traditional type of setup is best. For whatever reason, it doesn't reorder the variables at all. 
library(RSNNS)

set.seed(1)
model <- mlp(train %>% select(-quality, -color) %>% scale(), train %>% select(quality) %>% scale(), size = 5, learnFuncParams = c(0.1), maxit = 50, inputsTest = test %>% select(-quality, -color) %>% scale(), targetsTest = test %>% select(quality) %>% scale())

predictions = predict(model, test %>% select(-quality, -color) %>% scale())
test %>% 
  select(-quality, -color) %>% 
  add_predictions(model)
  mutate(pred = predict(fit, test)) %>% 
   summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N,
  )


```

```{r}
library(caret)
set.seed(1)
trControl <- trainControl(method  = "cv",
                          number  = 10)

fit <- train(color ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = 1:20),
             trControl  = trControl,
             metric     = "Accuracy",
             preProcess = c("scale", "BoxCox"), 
             data       = train)

test %>% 
  mutate(predictions = predict(fit, test)) %>% 
  select(color, predictions) %>% 
  table()

set.seed(1)
trControl <- trainControl(method  = "cv",
                          number  = 10)

fit2 <- train(color ~ .,
             method     = "knn",
             tuneLength = 9,
             trControl  = trControl,
             metric     = "Accuracy",
             preProcess = c("scale", "BoxCox"), 
             data       = train)

test %>% 
  mutate(predictions = predict(fit2, test)) %>% 
  select(color, predictions) %>% 
  table()



```

# OLS and PCA to make predictions
```{r}

mod1 = lm(quality ~., data = train %>% 
            select(-color))

test %>% 
  add_predictions(mod1) %>% 
   summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N,
  )

pc_train = train %>% 
  select(-color, -quality) %>% 
  scale() %>% 
  prcomp()

train_pc = pc_train$x %>% 
  as_tibble() %>% 
  bind_cols(train) %>% 
  select(PC1, PC2, PC3:PC10, quality)

pc_test = test %>% 
  select(-color, -quality) %>% 
  scale() %>% 
  prcomp()

test_pc = pc_test$x %>% 
  as_tibble() %>% 
  bind_cols(test) %>% 
  select(PC1, PC2, PC3:PC10, quality)

mod2 = lm(quality ~., data = train_pc)


test_pc %>% 
  add_predictions(mod2) %>% 
   summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N,
  )


test_pc %>% 
  add_predictions(mod2) %>% 
  mutate(pred = round(pred)) %>% 
  select(quality, pred) %>% 
  table()

  

mod_select = ols_step_all_possible(mod2)

mod_select %>% 
  arrange(desc())

test_pc %>% 
  add_predictions(mod3) %>% 
   summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N,
  )

test_pc %>% 
  add_predictions(mod3) %>% 
  mutate(pred = round(pred)) %>% 
  select(quality, pred) %>% 
  mutate(wrong = ifelse(quality != pred, 1, 0)) %>% 
  group_by(quality) %>% 
  summarize(
    N = n(), wrong = sum(wrong)/N
  )

pc_train$x %>%
  as_tibble() %>% 
  select(PC1, PC2) %>% 
  cor()

PCs = pc_train$x %>% 
  as_tibble()

sum(var(PCs$PC1) + var(PCs$PC2) + var(PCs$PC3) + var(PCs$PC4) + var(PCs$PC5))/sum(pc_train$sdev*pc_train$sdev)

# determining variable importance
correlation_matrix = pc_train$x %>% 
  as_tibble() %>% 
  bind_cols(train) %>% 
  select(-quality, -color) %>% 
  cor() %>% 
  as_tibble()

pc_train$x %>% 
  as_tibble() %>% 
  bind_cols(train) %>% 
  ggplot(aes(x = total.sulfur.dioxide, y = PC1)) +
  geom_point()
   
```
```{r}
df = read_csv("wine_df_scaled.csv")

# No the data are not approximately bivariate normal. They failed the test for normality and points on the chi-square plot appear to fall away from the line.
mvn(data = df %>% 
      select(-color, -quality) %>% 
      sample_frac(0.75), multivariatePlot = "qq")

```

# Transform dataset to multivariate normal
```{r}
df = df %>% 
  select(-color)

xBar = apply(df, 2, mean)

mu0 = xBar

HotellingsT2(df, mu = mu0, test = "chi")


tranformValues = powerTransform(df %>% select(-color, -quality))


df1 = df %>%
  select(-quality, -color) %>% 
  mutate(fixed.acidity = bcPower(df$fixed.acidity, -2.9989015)) %>% 
  mutate(volatile.acidity = bcPower(df$volatile.acidity, -0.2684332)) %>% 
  mutate(citric.acid = bcPower(df$citric.acid, 0.1626145)) %>% 
  mutate(residual.sugar = bcPower(df$residual.sugar, -1.7560426)) %>% 
  mutate(chlorides = bcPower(df$chlorides, -2.3583247)) %>% 
  mutate(free.sulfur.dioxide = bcPower(df$free.sulfur.dioxide, 0.1875227)) %>% 
  mutate(total.sulfur.dioxide = bcPower(df$total.sulfur.dioxide, 0.1030885)) %>% 
  mutate(density = bcPower(df$density, -3.0000000)) %>% 
  mutate(pH = bcPower(df$pH, -2.9988362)) %>% 
  mutate(sulphates = bcPower(df$sulphates, -0.5829286)) %>% 
  mutate(alcohol = bcPower(df$alcohol, -2.8481430))

mvn(df1 %>% sample_frac(0.75), multivariatePlot = "qq")

mvn(data = df %>% 
  mutate(tNO2 = bcPower(df$NO2, -0.164)) %>% 
  mutate(tO3 = bcPower(df$O3, 0.238)) %>% 
  select(tO3, tNO2), multivariatePlot = "qq")



```
# Feature Importance with RF and Permutation testing
```{r}

df = df %>% 
  mutate(color = as.factor(color))
set.seed(1)
data_vector = sample(1:6497, (0.8*6497))
train = df[data_vector, 1:13]
test = df[-data_vector, 1:13]

form = as.formula("quality ~ alcohol + color + sulphates + pH + density + total.sulfur.dioxide + free.sulfur.dioxide + chlorides + residual.sugar + volatile.acidity + fixed.acidity")

mod1 = randomForest(form, train, ntree = 1000,  mtry = 4, importance = TRUE)

train %>% 
  add_predictions(mod1) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N,
  )

MSE = test %>% 
  add_predictions(mod1) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N,
  )

MSE0 = MSE$MSE

variable = rownames(mod1$importanceSD %>% 
  data.frame())

value = mod1$importanceSD %>% 
  data.frame() %>% 
  rename(value = matches("."))

importance0 = cbind(variable, value) %>% 
  mutate(permuted = "No")


importanceList = list()
MseList = list()
n = c(1:100)

for(i in n) {
  
set.seed(i)
mod2 = randomForest(form, train %>% mutate(quality = shuffle(train$quality, replace = F)), ntree = 1000,  mtry = 4, importance = TRUE)

variable = rownames(mod2$importanceSD %>% 
  data.frame())

value = mod2$importanceSD %>% 
  data.frame() %>% 
  rename(value = matches("."))

importanceList[[i]] = cbind(variable, value)

MseList[[i]] = test %>% 
  add_predictions(mod2) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )
}


importance1 = bind_rows(importanceList) %>% 
  mutate(permuted = "Yes")

importance2 = importance1 %>% 
  bind_rows(importance0)

importance2 %>% 
  ggplot(aes(x = variable, y = value, color = permuted)) +
  geom_point() + theme(axis.text.x = element_text(angle = 45, hjust = 1))

MSE1 = bind_rows(MseList)
MSE1 %>% 
  ggplot(aes(x = MSE)) + 
    geom_histogram(aes(y=..density..), colour = "black", fill = "white", bins = 30) +
    geom_density(alpha = 0.2, fill = "#FF6666") +
    geom_vline(aes(xintercept = MSE0), colour = "red")

cforest(formula = form, data = train)

```
# CAR score for variable selection - potentially better than lasso?!
```{r}
set.seed(1)
X = model.matrix(quality ~., data = train)[, -1]
Xtest = model.matrix(quality ~., data = test)[, -1]
Y = train$quality %>% na.omit()
Ytest = test$quality

library(care)

carScore = carscore(Xtrain = X, Ytrain = Y, lambda = 0.0029, diagonal = F)

variable = rownames(carScore[1:12] %>% 
  data.frame())
value = carScore[1:12] %>% 
  data.frame() %>% 
  rename(score = matches(".")) 

results = cbind(variable, value) %>% 
  mutate(scoreSqrd = score^2) %>% 
  mutate(permuted = "No")

resultsList = list()
n = c(1:100)

for(i in n) {

set.seed(i)
carScore = carscore(Xtrain = X, Ytrain =  shuffle(Y, replace = F), diagonal = F)

variable = rownames(carScore[1:12] %>% 
  data.frame())
value = carScore[1:12] %>% 
  data.frame() %>% 
  rename(score = matches(".")) 
resultsList[[i]] = cbind(variable, value) %>% 
  mutate(scoreSqrd = score^2) 
}

results1 = results %>% 
  bind_rows(bind_rows(resultsList) %>% 
  mutate(permuted = "Yes") %>% 
    sample_frac(0.2))

results1 %>% 
  ggplot(aes(x = variable, y = scoreSqrd, color = permuted)) +
  geom_point() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_jitter(position = position_jitter(0.3))

```

# PCR Idea for cluster color
```{r}

set.seed(1)
data_vector = sample(1:6497, (0.8*6497))
train = df[data_vector, 1:13]
test = df[-data_vector, 1:13]

pc = train %>% 
  select(-color) %>% 
  scale() %>% 
  as_tibble() %>%  
  prcomp()

pcDf = pc$x %>% 
  as_tibble() %>% 
  bind_cols(train %>% 
              select(color)) %>% 
  select(PC1, PC2, PC3, color)

set.seed(1)
pcDf %>%
  sample_frac(0.25) %>% 
  ggplot(aes(x = PC1, y = PC3, color = color)) + 
  geom_point()

set.seed(1)
pcDf %>%
  sample_frac(0.25) %>% 
  ggplot(aes(x = PC1, y = PC2, color = color)) + 
  geom_point()

library(caret)
set.seed(1)
trControl <- trainControl(method  = "cv",
                          number  = 10)

fit <- train(color ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = 1:20),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = pcDf)

pc2 = test %>% 
  select(-color) %>% 
  scale() %>% 
  as_tibble() %>% 
  prcomp()

pcDf2 = pc2$x %>% 
  as_tibble() %>% 
  bind_cols(test %>% 
              select(color)) %>% 
  select(PC1, PC2, PC3, color)

pcDf2 %>% 
  mutate(predictions = predict(fit, pcDf2)) %>% 
  select(color, predictions) %>% 
  table()
```

# Splines
```{r}
library(splines)

df = read_csv("wine_df_scaled.csv")
df = df %>% 
  select(-color) %>% 
  scale() %>% 
  data.frame()

set.seed(1)
data_vector = sample(1:6497, (0.8*6497))
train = df[data_vector, 1:12]
test = df[-data_vector, 1:12]

# Spline
mod0 = lm(quality ~ alcohol + sulphates, data = train)

test %>% 
  add_predictions(mod0) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )

mod1 = lm(quality ~ ns(alcohol, df = 16), data = train)

test %>% 
  add_predictions(mod1) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )

mod2 = lm(quality ~ ns(alcohol, df = 4), data = train)

test %>% 
  add_predictions(mod2) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )

# GAM
library(gam)
mod1 = lm(quality ~ ns(alcohol, df = 16) + bs(volatile.acidity, df = 16) + ns(total.sulfur.dioxide, df = 16), data = train)

test %>% 
  add_predictions(mod1) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )

# RandomForest
mod3 = randomForest(quality ~., train, ntree = 1000,  mtry = 4, importance = TRUE)

# Test MSE
test %>% 
  add_predictions(mod3) %>% 
  summarize(
    N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
  )

# form = as.formula("quality ~ alcohol + volatile.acidity + total.sulfur.dioxide + sulphates + residual.sugar + free.sulfur.dioxide + chlorides")
# 
# mod4 = randomForest(form, train, ntree = 1000,  mtry = 3, importance = TRUE)
# 
# # Test MSE
# test %>% 
#   add_predictions(mod4) %>% 
#   summarize(
#     N = n(), SSE = sum((pred - quality)*(pred - quality)), MSE = SSE/N
#   )

randomForest

```



